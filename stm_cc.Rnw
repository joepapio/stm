\documentclass{article}
\usepackage[margin=1.25in]{geometry}
\usepackage{pdfpages, natbib}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[utf8]{inputenc}

\setlength{\parskip}{.5em}

\newcommand{\hh}[1]{{\color{magenta} #1}} 

\newcommand{\jp}[1]{{\color{blue}#1}}

\newcommand{\R}{\mathbb{R}}

\title{What Voters are Talking About\\
\vspace*{1\baselineskip}
\large Applying the Structural Topic Model to Open Ended Survey Responses \\
from the American National Election Studies}

\author{Joseph Eduardo Papio\\
\vspace*{1\baselineskip}
\small Iowa State University}

\begin{document}

\maketitle

<<concordance, echo=FALSE, warning=FALSE, message=FALSE>>=
opts_knit$set(self.contained=FALSE, cache=TRUE, width=40)
library(tidyverse)
library(quanteda)
library(RColorBrewer)
library(stm)
library(ggrepel)
library(forcats)

# save(feelC.FX, scree2, partyQ.clouds1,  partyQ.clouds2, partyQc.FX, feel.clouds1,feel.clouds2, feel.FREX, year.FREX, file="objsForPaper.Rdata")
# save(year.FX, party.FX, race.int2.FX, gen.int2.FX, edu.int2.FX, inc.int2.FX, ide.int2.FX, chu.int2.FX, file="FX.Rdata")
load(file="objsForPaper.Rdata")
load(file="FX.Rdata")

str_break = function(x, width = 70L) {
  n = nchar(x)
  if (n <= width) return(x)
  n1 = seq(1L, n, by = width)
  n2 = seq(width, n, by = width)
  if (n %% width != 0) n2 = c(n2, n)
  substring(x, n1, n2)
}

normy <- function(x){
  x %>% mutate(
    normed = props/sum(props)) %>% 
    group_by(tops) %>%
    summarize(total = sum(normed)) %>%
    arrange(desc(total)) %>% mutate(
      ord = 1:length(total)
    )
}

chop1 <- function(x, n=50){
  x %>% arrange(desc(proportion)) %>% slice(1:n)
}

example1 <-"He has turned his back on the coal and steel industry in favor of importing from foreign countries.  He has West Virginia, Ohio, and Pennsylvania on its knees."

example2 <- dfm(example1, stem=TRUE, removeNumbers=TRUE, 
                 removePunct=TRUE, removeSeparators=TRUE,
                 ignoredFeatures=c(stopwords("english"), 
                                   "na", "ao", "wm", "tm", "ae", "ge"))

example3 <- "I think my husband's disability and our social security is in danger.  He will cut this and the disability is my husband's only income.  He has already cut some out of our check."

example4 <- dfm(gsub("social security", "socialsecurity", example3), stem=TRUE, 
                removeNumbers=TRUE, removePunct=TRUE, removeSeparators=TRUE, 
                ignoredFeatures=c(stopwords("english"), 
                                   "na", "ao", "wm", "tm", "ae", "ge"))
@

\section{Introduction, Motivation, and Literature Review}

\subsection{Open Ended versus Traditional Surveys}
 
Open ended survey questions provide an opportunity to solicit unguided opinions and ideas from participants, avoiding possible biases that can be introduced when utilizing more traditional survey forms in which respondents are prompted to select their answer from one of several predetermined options in a closed set of choices. The immediate benefit of such traditional survey formats is that once the data are collected, the analysis, including estimation of the prevalence of those opinions within the population, is fairly straight forward. Such analysis generally requires a relatively low amounts of personnel power and computational resources. However, by prompting respondents to select from among a set of predetermined choices which must be decided upon by researchers prior to implementation, ideas which are already present in the political collective consciousness but not yet salient to researchers may not be captured by the study. Considering such information loss, exploration and application of of open ended (and thus ``unprimed") survey responses is an area of great interest and potential in the humanities and social sciences.

Unlike analysis of more traditionally formatted surveys, open ended surveys require a much larger resource investment to analyze. Prior to analysis, the data often require large amounts of in person processing to read and code the responses. Readers must be trained before they can perform the task of reading through responses and then use their judgement to decide what topic or topics each open ended response is about, often selecting those topics from options generated by the researchers. Thus, in addition to the large resource requirements, some topical information contained in the responses may still go still go unrecognized when utilizing this method of analyzing open ended surveys, particularly if that topical information does not fit neatly into any of the options predetermined by researchers or readers.

However, as computing power increases, interest in the development, exploration, and application of automated textual analysis methods such as topic models continues to grow, especially for humanities and social science researchers. Such interest is likely to be stronger with researchers who are required to first build survey instruments before interacting with respondents, as the time required to construct the instruments prior to deployment can introduce significant lag. During such time, nascent ideas forming within the population may be missed or detected by other researchers.

\subsection{pLSI, LDA, and STM}

Topic models are a relatively new subfield of Machine Learning and Natural Language Processing. Collectively they represent an effort to bring some level of automation, speed, and reliability to quantifying the latent thematic information present in text responses. Such efforts can be applied to texts of varying sizes, including the open ended surveys we analyze here. Thus, in the past two decades of their development, they have shown great promise for reducing the resource burdens mentioned previously.

Probabilistic Latent Semantic Indexing (pLSI) was one of the earliest forms of topic modeling to be proposed  \citep{hofmann:1999}. pLSI is derived from latent class modeling for factor analysis of count data. It relies on associating latent class variables, I.E. topics, with how observed data (words) co-occur. Despite many limitations, pLSI was a pioneering step in the development of the foundation for the Topic Models framework. 

Latent Dirichlet Allocation (LDA) \citep{LDA2003} built on the work of pLSI by introducing distributional assumptions. Blei, Ng and Jordan assume both documents within the corpus and words within the document are exchangeable, which is to say the order does not matter, and any word/document can come before or after any other word/document. This treatment of words within a document is referred to as the ``bag of words" approach.  Although this approach with respect to the words within a document causes some loss of syntactic information, particularly in a language like English where the word ordering often conveys meaning about the grammatical relationships between words, this is not a major concern for topic modeling, since the primary focus is on ascertaining the semantic and thematic content of the set of documents in question.  \citet{LDA2003} presumably chose the Dirichlet distribution because it allows the specification of a multidimensional simplex, from which multinomial distributions can be readily generated. In particular, when the $\alpha_i$ parameters are $\leq 1$, as this pushes the drawn multinomials towards an ``edge" of the simplex. The edge, unlike the unlike the ``center" of the Dirichlet, redistributes probability away from some outcomes (topics) and towards to others.  This is different from the assumptions made (or rather, not made) by pLSI, where all topics have some non negligible probability for each document.

Blei further builds on LDA, addressing the somewhat unrealistic expectation with respect to large collections of documents that there is no correlation among topics or documents, with the introduction of Correlated Topic models \citep{Blei:2007jy}. For example, within the peer reviewed literature of a given field, we expect that articles written at a later date will be influenced to some degree by articles that were published previously. Thus, correlated topic models build on LDA by relaxing assumption that documents are independent and identically distributed.

Further developments in topic modeling include the Dirichlet-multinomial Regression model to allow covariates to affect topic prevalence \citep{TMCAFDMR} and change the rate at which a topic appears in a given document and allowing topic content to vary in log-frequency from a the background/mean \citep{SAGM}, thus allowing respondents to discuss a given topic at the same rate but in different ways (I.E. using different words).

Taking these developments and combining them, Structural Topic Models (STM) \citep{stm2013} offer a general framework to allow the inclusion of document level covariates which can influence either the rate at which a topic appears in a document \textit{or} what words are more or less likely to be used when a given topic is discussed by different groups. In the open ended surveys analyzed here, the covariates explored include the year of the election, demographic information about the respondent (race, gender, income, education, ideology, church attendance and party affiliation), the candidate's political party, and whether the thing the respondent mentions in their response is likely to make them vote \textit{for} (like) or \textit{against} (dislike) that candidate.

\citet{stm2013} apply their Structural Topic Model to open ended survey data from the American National Election Studies (ANES) collected in 2008 in which respondents were asked to identify the two most important political problems facing the United States and personal issues in the election. 


\section{Methodology}

\subsection{Definitions}
STM, like LDA and other topic models, assumes an underlying process involving unobserved semantic units, which we define as ``topics", generates the data (words and documents) we observe. The observational units are defined to be the words we see in the documents. The set of all documents, $\mathcal{D}$, is said to be the corpus. We denote the size of the corpus $D$, indexing documents by $d \in \{1...D\}$. Each document is composed of a set of words, denoted \{$w_{n,d}$\}, for $n \in \{1...N_d\}$, where $N_d$ is the number of words in the $d$-th document. Abstracted from the corpus is the vocabulary, a vector of all the unique words and features observed within the corpus. The terms in the vocabulary are denoted by $v \in \{1...V\}$, where features are derived from documents. There are many possible ways to derive features. In this setting, we include unigrams and selected digrams as features. Digrams are word strings of length 2, such as ``vice president" or ``social security", which convey meaning in a political context beyond the individual items such as  ``vice" and ``president" or ``social" and ``security" separately. Lastly, based on some trial and error, or perhaps based on other studies, we specify the number of topics, denoted $k \in \{1...K\}$.

Topics, as latent units of meaning, exist within the corpus as non exclusive groups of words which have high co-occurrence within documents. Words, as members of the vocabulary, are not exclusive to any particular topic, but rather can occur in multiple topics with varying prevalence, something desirable for languages in which some words can have multiple unrelated meanings. Once the number of topics is determined and the set of topics is computed, we can then estimate the proportions of each topic in each document, as well as how our selected covariates affect these proportions. Summing over sets of documents or over all documents give us the proportions of topics within sub groups by covariates or within the corpus as a whole.

\subsection{Data Generating Process}

The data generating process is presumed as follows:

\begin{itemize}
\item For $d \in \{1...D\}$, draw vector $\theta_d$, an element of the K-simplex (I.E. $\{x \in \R^k | 0\leq x_i\leq 1, \sum^K_{i=1}x_i=1\}$ ), specifying probabilities for selecting from the available topics.

\item For $w_{d,n}$, with $d \in \{1...D\}$, and $n \in \{1...N_d\}$, draw a topic $z_{d,n} \in \{1...K\}$, a vector specifying probabilities over words in the vocabulary.

\item For $w_{d,n}$, with $d \in \{1...D\}$, and $n \in \{1...N_d\}$, draw a specific word $v$ from the vocabulary, dictated by the vector $z_{d,n}$. 
\end{itemize}

Based on this process, inference on the structure of the $K$ topics in the corpus flows in reverse, starting from the observed words and working back identify the distributions over the vocabulary and the effects the covariates have on the rates of those topics appearing in documents and in the corpus. 

Most topic models rely on Bayesian methods for computation, and thus require prior distributions be specified for analysis. However, where LDA, operating on the assumption that a single data generating process undergirds the entire corpus (in which documents are exchangeable with one another), and thus places a single global Dirichlet prior on the Multinomials that select the topics, STM instead assumes that arbitrary groups of documents specified by levels of a corvariate or set of covariates are governed by a set of priors with a Logistic Normal Distribution. This is what is presumed to make some documents in group (I.E. covariate level) $A$ to be more about topic $t$ whereas documents in group $B$ can be more about topic $s$. 

\subsection{General Model Specifications}

The Structural Topic Model is essentially a combination and generalization of three separate topic models, the Core Language Model, which builds off the Correlated Topic Model \citep{Blei:2007jy}, the Topic Prevalence Model, developed in \citet{TMCAFDMR}, and the Topical Content Model, developed in \citet{SAGM}. Analysts can opt to leave out one of the latter two components if not pertinent to their questions of interest \citep{stm2016}.

Presuming the use of both prevalence and content covariates, for a corpus of size $D$ documents,  observed words $\{w_{d,n}\}$ in those documents, a specified number of topics $K$, vocabulary of size $V$, a design matrix of topic prevalence covariates denoted $\mathbf{X}$, and another design matrix of topical content covariates denoted $\mathbf{Y}$, the distributions involved are as follows:

\begin{centering}
\begin{align}
	\gamma_{k} &\sim \text{Normal}_P(0, \sigma^2_kI_P), & for \, k=1...K-1 \\
	\sigma^2_k &\sim \text{Inverse-Gamma}(a,b )\\ 
	\mathbf{\theta}_d &\sim \text{LogisticNormal}_{K-1}(\mathbf{\Gamma'}\mathbf{x}'_d,\mathbf{\Sigma}) \\
	\mathbf{z}_{d,n} &\sim \text{Multinomial}_K(\mathbf{\theta}_d) & for \, n=1...N_d\\
	\mathbf{w}_{d,n} &\sim \text{Multinomial}_V(\mathbf{\beta}_{z_{d,n}}) &  for \, n = 1...N_d\\
	\beta_{d,k,v} & = \frac{exp(m_v + \kappa^{(t)}_{k,v} + \kappa^{(c)}_{y_d,v} + \kappa^{(i)}_{y_d,k,v } )} {\Sigma_v exp(m_v + \kappa^{(t)}_{k,v} + \kappa^{(c)}_{y_d,v } + \kappa^{(i)}_{y_d,k,v} ) } & for \, v=1...V \, and \, k=1...K
\end{align}
\end{centering}

$\gamma_k$ is a vector with length P, where P is the dimensions of prevalence covariate levels and interactions. The individual $\gamma_k$s together form $\Gamma$, a $P \times (K-1)$ matrix of coefficients that specify which cofactor levels influence the prevalence of which topics. $a$ and $b$ are generalized hyperparameters for $\sigma^2$. $\beta_{z_{d,n}}$ specifies a distribution over the vocabulary, continent on the topic and the content covariates. $m_v$ represents the marginal log-transformed corpus rate for term $v$. {$\kappa^{(t)}_{.,.},\kappa^{(c)}_{.,.},\kappa^{(i)}_{.,.}$} is a collection of coefficients for the topical content model. The remaining parameters were defined in the previous subsection. 

Then the full posterior involved in the model is $p(\mathbf {\eta, z,\kappa, \gamma, \Sigma} |\mathbf{w, X, Y }) \propto$
\begin{equation}
\bigg(\prod^D_{d=1}Normal(\mathbf{\eta_d}|\mathbf{X}_d\mathbf{\gamma}, \mathbf{\Sigma}) \Big(\prod^N_{n=1}Mult(z_{n,d}|\mathbf{\theta}_d) \times Mult(w_n|\mathbf{\beta}_{d,k=z_{d,n}} \Big) \bigg) \times \Pi p(\kappa) \Pi p(\mathbf{\Gamma})
\end{equation}

\subsection{Estimation}

The posterior given in the previous subsection is intractable to any closed form evaluation. \citet{stm2016} utilize an approximate variational Expectation Maximization (EM) algorithm developed by \citet{WangBlei2013}. This involves finding the approximate posterior $\Pi_d q(\mathbf{\eta}_d)q(\mathbf{z}_d)$ where $q(\mathbf{\eta}_d)$ is a Gaussian with mean $\lambda_d$ and covariance $v_d$ and $q(\mathbf{z}_d)$ is a multinomial with parameter $\phi_d$, where $\phi_{d,n,k} \propto exp(\lambda_{d,k})\beta_{d,k,w_n}$ and where $\lambda_k$ is an outcome variable of the M-step.

In the E-step, the algorithm iterates through each document, updating variational posteriors $q(\mathbf{\eta}_d)$ and $q(\mathbf{z}_d)$. In the M-step, the algorithm maximizes the the approximate ``Evidence Lower Bound" \citep{WangBlei2013} with respect to $\mathbf{\Gamma}$, $\mathbf{\Sigma}$, and $\mathbf{\kappa}$ and updates coefficients in the topic prevalence model, topic model, and global covariance matrix. As with other EM algorithms, these steps are iterated until convergence is said to be met, once changes are smaller than some (small) prespecified value.

\section{Application}
\subsection{Data: American National Election Studies}
The American National Election Studies has been collecting survey data on elections in the United States since 1948. In addition to numerous traditional survey forms, they have also consistently asked several questions which elicit open ended responses from participants. These include the ``like/dislike" questions, which have been collected both on the two major US political parties and their congressional candidates during most presidential and midterm elections as well as for the parties' presidential candidates during presidential election years.  For this analysis, we focus on the ``like/dislike" responses specifically for presidential candidates of the two major parties, which read as follows:
\begin{quote}
Now I'd like to ask you about the good and bad points of the two candidates for President. Is there anything in particular about [Democratic presidential candidate]/[Republican presidential candidate] that might make you want to vote \textit{for} him?  What is that? Anything else?
\end{quote}
\begin{quote}
Is there anything in particular about [Democratic presidential candidate]/[Republican presidential candidate] that might make you want to vote \textit{against} him? What is that?  Anything else?
\end{quote}
While the ANES has collected open ended responses to these questions over many years, little has been done with them due to the high cost of analysis referenced in the introduction. We apply the Structural Topic Model to a subset of these open ended surveys, collected during presidential election years, from Ronald Reagan's reelection campaign of 1984 to George W. Bush's reelection campaign of 2004. Although the ANES also collected similar responses on the independent candidate, Ross Perot, in 1992 and 1996, we have omitted these data from the analysis to be consistent across all six years. In addition to the open ended survey responses, the ANES also collects basic demographic information on each respondent. From this massive set of potential covariates, we selected the year the responses were collected, as well as the respondents' race, gender, political affiliation, church attendance, educational attainment, income percentile, and ideology, as covariates to fit and examine.

\subsection{Text Pre-Processing}

To prepare the open ended survey responses for analysis, we first applied some standard text preprocessing. Although the STM package includes some functions from the text mining \citep{tm} package, we opted to use the quanteda \citep{quanteda} package, since it offers more flexibility and its output could easily be converted into an object which the stm package could utilize. This process involved several steps:
\begin{enumerate}
\item remove punctuation
\item stemming
\item partial digramming
\item stop word removal (I.E., removal of generally very high frequency features)
\item very low frequency feature removal
\end{enumerate}
Stemming (2) ensures that words like ``immigrant" and ``immigrants" and ``immigration" are recognized as a single feature within the corpus, rather than three separate features. An n-gram is an $n$ length string of words . As noted previously, ``partial digramming" (3) retains most features in the vocabulary as single words (I.E. unigrams), but blends certain phrases of two word length into single features, so that, for example, ``vice president" or ``social security" are recognized as single features, rather than two separate features, and are thus recognized by our model as a different features than ``president" or ``security" respectively. We opted for ``partial digramming" rather than using digrams of the entire corpus, since models using just unigrams or all uni- and digrams generated fairly similar models, but topic estimation for models using all possible uni- and digrams took significantly longer amounts of time to run, and not all converged. Stop word removal (4) involves filtering out a standard set of English ``function" words, including most articles and prepositions, as well as some corpus specific features, like ``ae" which indicates that the interviewer asked ``Anything else?" Lastly, (5) very low frequency words ($n \leq 3$ instances) which might slow computation but add nothing to the interpret ability of the model are also removed. 

Two example responses are given below, showing first the unprocessed response followed by a ``toy" document feature matrix representing a corpus of only that individual document. Document feature matrices representing corpora with more than one document will almost always have numerous entries which are zero, since two documents will rarely if ever be represented by exactly the same vocabulary. 

Example 1: Original text
<<ex1orig, eval=TRUE, echo=FALSE>>=
print(str_break(example1))
@
Example 1: Preprocessed text
<<ex1prepro, eval=TRUE, echo=FALSE>>=
rbind(example2@Dimnames$features, example2@x)
@
Example 2: Original text
<<ex2orig, eval=TRUE, echo=FALSE>>=
print(str_break(example3))
@
Example 2: Preprocessed text
<<ex2prepro, eval=TRUE, echo=FALSE>>=
rbind(example4@Dimnames$features, example4@x)
@

After this preprocessing of the corpus, the remaining dataset contains 23,507 instances of open ended responses with counts for 3,357 features (unigrams and selected digrams). This corresponds to 9,977 individuals who responded to between one and four of these questions over the course of six presidential elections, taking place every four years between 1984 and 2004.

The corpus is then represented by a 23,507 rows by 3,357 columns document feature matrix, in which the $d$-th row corresponds to the $d$-th document and the $v$-th column represents the $v$-th feature in the vocabulary. Then the $d,v$-th entry in the matrix represents the number of times the $v$-th feature occurs in the $d$-th document. This matrix is very sparse, with the vast majority of entries being zeros. The estimation process outline in the previous section reduces the dimension of the columns from 3,357 features to 60 topics.

\subsection{ANES Models}

After exploring simple models with various numbers of topics, we settled on models using $K=60$ topics. This is close to the number of topics ($K=69$) which \citet{stm2013} fit for their analysis of a open ended survey data from the ANES for the 2008 election, inquiring about the top issues of the campaign, for which they were also able to obtain and compare hand coded analysis.

As a baseline model, we fit only the election year as a covariate. Rather than fitting this as a linear coefficient, we opted for a categorical variable to avoid forcing the prevalence of a given topic to either strictly increase or strictly decrease over time. This model is similar to the model presented in \citet{dtm2006}.

In addition to the year, further models add the respondent's party ID and also included one of the selected covariates (respondent's race, gender, income percentile, educational attainment, church attendance, or ideology). While our intention had been to examine how topics and topic proportions differ when models with different covariates are fit, none of the models fit appear to be particularly different. Models fit with different covariates yielded essentially the same topics, with minor differences in word prevalence within topics or topics within documents when compared via screeplots or word clouds. However, these visualizations, which still yield valuable and interesting insights into the open ended survey corpus, will be discussed in the following section.

\section{Contextualizing the findings: Discussion and Visualization}

Perhaps the most fun and also the most frustrating part of this project was considering ways to summarize the information gleaned from fitting the various models. While it is our hope that as scholars continue to use and explore these procedures, more easily assessable metrics of fit will be developed, we focus mostly on graphical examinations at this juncture. We produce plots of topic proportions to show some variation in topic prevalence across years and also by selected covariates. We incorporate expert political science opinion of American elections via examination of wordclouds and exemplar responses for particular topics in order to identify which topics are semantically coherent and what those topics pertain to. We also produce screeplots to determine how particular words contribute to the structure of particular topics, as well as how particular topics contribute to the structure of the corpus or subsets of the corpus.

While there may be some effects demographic covariates have on topic proportions from respondents or how those respondents discussed certain topics, we were unable to detect a strong enough signal to say so any certainty or qualitative rigor. However, the models and the overall process of studying their output have produced opportunities for qualitative analysis and comparisons. Incorporating solid visualization techniques, some insights from the models are discussed below.

Most of the visualizations done throughout this paper leverage the amazing power and flexibility of ggplot \citep{ggplot2} and other packages within tidyverse \citep{tidyverse} to ``wrassle" data into tidy structures and then make plots more dynamic and informative, something which is much harder to do efficiently when relying on the base R plotting functionality, as is the case with the STM package \citep{stmR}.

\subsection{Simultaneous plotting of multiple covariates}
To better visualize how topic prevalence varies within the corpus conditioned on particular covariates, we used tidyr and dplyr to reparameterize coefficients, then plot multiple covariates simultaneously, rather than just one at a time, as with the stm/base R plotting functionality. Below we present an example of a plot for a single topic, followed by an example of a plot offering a broad overview of the topic distributions affected by respondent covariates. 

We start with a relatively simple example, Figure \ref{yearEx}, in which we compare only a single covariate to the topic proportions, by placing election year on the x-axis and the proportion this topic appears in the corpus conditioned on that year on the y-axis. For this plot, we include the names of the candidates for that year, with the winner of that election listed first.
\begin{figure}[H]
<<yearEX, echo=FALSE, fig.width= 6, fig.height=4>>=
year.FX %>%  filter(topic ==48) %>%
  mutate(yearf = fct_recode(yearf,
                            c("1984 \n Ronald Reagan \n Walter Mondale"="1984",
                              "1988 \n George HW Bush \n Michael Dukakis"="1988",
                              "1992 \n Bill Clinton \n George HW Bush"="1992",
                              "1996 \n Bill Clinton \n Bob Dole"="1996",
                              "2000 \n George W Bush \n Al Gore"="2000",
                              "2004 \n George W Bush \n John Kerry"="2004"))) %>%
  ggplot(aes(x=yearf, y=beta)) +
  geom_point() +
   ylim(0,.04) +
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
  theme(axis.text.x=element_text(angle=90, vjust=0.5), plot.title = element_text(hjust=0.5)) +
  ggtitle("Mean Proportion for Topic 48 for each Election Year")
@
\caption{\label{yearEx} Proportion plot for topic 48, regarding campaign tactics, with prevalence conditioned on election year. Remaining between 1\% - 2\% of the corpus each year, this topic can almost be considered ``background noise".}
\end{figure}
Next we take use the same plotting method, but zoom out to an overview of the corpus, plotting all topics simultaneously while incorporating additional covariates. In Figures \ref{simcovsA} and \ref{simcovsB}, we see how much a topic appears in the corpus, conditioned on election year, the voter's party, and the candidate's party.  Election year and topic proportion remain on the x-axis and y-axis, respectively. We map the candidate's party to the shape of the point, and use color to indicate the voter's party affiliation. The remainder of these plots involving other covariates are presented in the Appendix.
\begin{figure}[H]
<<simcovsA, echo=FALSE, fig.width= 7.7, fig.height=9.2>>=
feelC.FX %>%  filter(topic %in% 1:30) %>%
  filter(partyID == "Rep" | 
           partyID == "Ind" | 
           partyID == "Dem") %>%
  ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes( shape=partyQ, color=partyID), alpha=0.7) +
  # ylim(0,.09) +
  guides(shape=guide_legend(title="Candidate"), color=guide_legend(title="Voter")) +
  facet_wrap(~topicf, ncol=3) + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
  theme(axis.text.x=element_text(angle=90, vjust=0.5), plot.title = element_text(hjust=0.5)) +
  ggtitle("Mean Topic Proportions for each Election Year \n based on Parties of Voters and Candidates")
@
\caption{\label{simcovsA} Proportions for Topics 1 through 30, conditioned on election year, respondent party affiliation, and candidate party.}
\end{figure}
\begin{figure}[H]
<<simcovsB, echo=FALSE, fig.width= 7.7, fig.height=9.2>>=
feelC.FX %>% filter(topic %in% 31:60) %>%
  filter(partyID == "Rep" | 
           partyID == "Ind" | 
           partyID == "Dem") %>%
  ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes( shape=partyQ, color=partyID), alpha=0.7) +
  # ylim(0,.09) +
  guides(shape=guide_legend(title="Candidate"), color=guide_legend(title="Voter")) +
  facet_wrap(~topicf, ncol=3) + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
  theme(axis.text.x=element_text(angle=90, vjust=0.5), plot.title = element_text(hjust=0.5)) +
  ggtitle("Mean Topic Proportions for each Election Year \n based on Parties of Voters and Candidates")
@
\caption{\label{simcovsB} Proportions for Topics 31 through 60, conditioned on election year, respondent party affiliation, and candidate party.}
\end{figure}
For the remainder of this subsection, we focus on proportions for specific topics, while also exploring a few of the other available demographic covariates. For example, as we can see in Figure \ref{top59prop}, there is a spike in the prevalence of Topic 59 in the 2000 presidential election. Both candidates discussed education frequently during that election \citep{edu2000}, and we can see that women were more likely than men to bring up this issue, particularly if they were democratic voters. Perhaps because of this, education was one of the earlier agenda items which the George W. Bush administration attempted to tackle, when he worked ``across the aisle" with Democrats to pass the now infamous No Child Left Behind.
\begin{figure}[H]
<<top59prop, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=3>>=
gen.int2.FX %>%  filter(topic==59) %>%
  filter(partyID == "Rep" | 
           partyID == "Ind" | 
           partyID == "Dem") %>%
  ggplot(aes(x=yearf, y=beta)) +
  # geom_point(aes(fill=feel, shape=partyQ), size=3) +
  geom_point(aes( shape=gender, color=partyID)) +
    ylim(0,.08) +
  #  facet_wrap(~feel) + 
  # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Year")+
   theme(axis.text.x=element_text(angle=90, vjust=0.5), plot.title = element_text(hjust=0.5)) +
    ggtitle("Proportions by Respondent Party and Gender for Topic 59")
@
\caption{\label{top59prop} Proportions for Topic 59, regarding education}
\end{figure}

Since the president serves as a stabilizing role within the country, presidential candidates' health, especially with respect to age, is frequently a topic in presidential elections. As we can see in Figure \ref{top51prop}, topic 59 shows up at higher than background rates in 1984, when Reagan was running for election after being the oldest person ever to serve in the office. In an attempt to diffuse the issue, he often joked about his age, for example, saying in a televised debate, ``I want you to know that also I will not make age an issue of this campaign. I am not going to exploit for political purposes my opponent's youth and inexperience" \citep{reagyouth}. The topic was also of higher prevalence in 1996, when relatively youthful sitting president Bill Clinton was challenged by much older Senator Bob Dole.

\begin{figure}[H]
<<top51prop, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=3>>=
partyQc.FX %>%  filter(topic==51) %>%
  filter(partyID == "Rep" | 
           partyID == "Ind" | 
           partyID == "Dem") %>%
  ggplot(aes(x=yearf, y=beta)) +
  # geom_point(aes(fill=feel, shape=partyQ), size=3) +
  geom_point(aes( shape=feel, color=partyID)) +
    ylim(0,.08) +
  #  facet_wrap(~feel) + 
  # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Year")+
    theme(axis.text.x=element_text(angle=90, vjust=0.5), plot.title = element_text(hjust=0.5)) +
    ggtitle("Proportions by Respondent Party and Sentiment for Topic 51")
@
\caption{\label{top51prop} Proportion of Topic 51, regarding age}
\end{figure}

Topic 17, which is about social and other non-economic factors, appears to go up steadily over the course of the 1980s and 1990s. Beyond that increase, Figure \ref{top17prop} further suggests a separation over time, with those with higher education rates bringing up the topic with increasing frequency in subsequent elections. This suggests social issues (``the culture war") have been a steadily increasing concern for the electorate.

\begin{figure}[H]
<<top17prop, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=3>>=
edu.int2.FX %>%  filter(topic==17) %>%
  filter(partyID == "Rep" | 
           partyID == "Ind" | 
           partyID == "Dem") %>%
  ggplot(aes(x=yearf, y=beta)) +
  # geom_point(aes(fill=feel, shape=partyQ), size=3) +
  geom_point(aes( shape=edu, color=partyID)) +
    ylim(0,.08) +
  #  facet_wrap(~feel) + 
  # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Year")+
    theme(axis.text.x=element_text(angle=90, vjust=0.5), plot.title = element_text(hjust=0.5)) +  
    ggtitle("Proportions by Respondent Party and Education for Topic 17")
@
\caption{\label{top17prop} Proportion of Topic 17, regarding social issues}
\end{figure}

Topic 35 concerns race. Perhaps unsurprisingly, given the state of racial awareness in the United States, we can see in Figure \ref{top35prop} that non white respondents appear to discuss race using terms that are more immediately obviously about race at higher rates than white respondents. However, this finding may be somewhat misleading, as white racial anxieties are often expressed via subtle ``dog whistle" language. Detecting such coded verbiage is likely beyond topic modeling's current capabilities.

\begin{figure}[H]
<<top35prop, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=3>>=
race.int2.FX %>%  filter(topic==35) %>%
  filter(partyID == "Rep" | 
           partyID == "Ind" | 
           partyID == "Dem") %>%
  ggplot(aes(x=yearf, y=beta)) +
  # geom_point(aes(fill=feel, shape=partyQ), size=3) +
  geom_point(aes( shape=race, color=partyID)) +
    ylim(0,.08) +
  #  facet_wrap(~feel) + 
  # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Year")+
     theme(axis.text.x=element_text(angle=90, vjust=0.5), plot.title = element_text(hjust=0.5)) + 
    ggtitle("Proportions by Respondent Party and Race for Topic 35")
@
\caption{\label{top35prop} Proportion of Topic 35, regarding race}
\end{figure}

Topics 18 (Figure \ref{top18prop}) and 23 (Figure \ref{top23prop}) both appear to relate to Bill Clinton and scandals, although topic 18 shows up across three consecutive elections (both of Clinton's, as well as Gore's) whereas topic 23 appears to be concentrated mostly in 1996 during Clinton's reelection, and may be particularly focused on the Watergate Scandal. Unsurprisingly, these scandal topics are brought up more frequently when asked for something they dislike about the candidate.

\begin{figure}[H]
<<top18prop, echo=FALSE,warning=FALSE,  fig.width= 6, fig.height=3>>=
partyQc.FX %>%  filter(topic==18) %>%
  filter(partyID == "Rep" | 
           partyID == "Ind" | 
           partyID == "Dem") %>%
  ggplot(aes(x=yearf, y=beta)) +
  # geom_point(aes(fill=feel, shape=partyQ), size=3) +
  geom_point(aes( shape=feel, color=partyID)) +
    ylim(0,.08) +
  #  facet_wrap(~feel) + 
  # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Year")+
    ggtitle("Proportions by Respondent Party and Sentiment for Topic 18")
@
\caption{\label{top18prop} Proportions for Topic 18, regarding Clinton/Scandal}
\end{figure}
\begin{figure}[H]
<<top23prop, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=3>>=
partyQc.FX %>%  filter(topic==23) %>%
  filter(partyID == "Rep" | 
           partyID == "Ind" | 
           partyID == "Dem") %>%
  ggplot(aes(x=yearf, y=beta)) +
  # geom_point(aes(fill=feel, shape=partyQ), size=3) +
  geom_point(aes( shape=feel, color=partyID)) +
    ylim(0,.08) +
  #  facet_wrap(~feel) + 
  # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Year")+
    ggtitle("Proportions by Respondent Party and Sentiment for Topic 23")
@
\caption{\label{top23prop} Proportions for Topic 23, regarding Clinton/Scandal}
\end{figure}

In a final example, Figure \ref{top54prop}, we see the impact income percentile has on the prevalence of topic 54, regarding the middle and working class. Although not a particularly surprising finding, across every year, we see that higher levels of income tend to co-occur with less discussion of the working and middle class. 

\begin{figure}[H]
<<top54prop, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=3>>=
inc.int2.FX %>%  filter(topic==54) %>%
  filter(partyID == "Rep" | 
           partyID == "Ind" | 
           partyID == "Dem") %>%
  filter(income!= "DK/NA") %>%
  ggplot(aes(x=yearf, y=beta)) +
  # geom_point(aes(fill=feel, shape=partyQ), size=3) +
  geom_point(aes( shape=income, color=partyID)) +
    ylim(0,.08) +
  #  facet_wrap(~feel) + 
  # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Year")+
    ggtitle("Proportions by Respondent Party and Income for Topic 54")
@
\caption{\label{top54prop} Proportions for Topic 54, regarding the working and middle class}
\end{figure}

\subsection{Screeplots}
To visually examine how elements of one level of the model contribute to higher elements of the model, we can plot the elements' contribution to the group against the rank of their contributions, essentially forming a screeplot. Thus we can examine how much particular words contribute to the make up of topics, as well as how much particular topics contribute both to the make up of parts of the corpus subset by covariates as well as to the overall make up of the corpus. Selected screeplots examining topic contributions to the corpus or subsets of the corpus, as well as those examining word contributions, are also presented below. The remaining screeplots are provided in the Appendix.

\begin{figure}[H]
<<sentbycandScree, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=4>>=
scree2 %>% 
  nest(-mood) %>% mutate(
    normed = purrr::map(data, normy)
  ) %>% select(mood, normed) %>% unnest() %>%
  ggplot(aes(y=total, x=ord)) +
  geom_text_repel(aes(label=ifelse(ord<11, tops, NA))) +
  geom_point() +
  facet_wrap(~mood) +
  labs(x = 'Order', y = 'Proportion contributed') + 
  ggtitle("Screeplots for topics separated out by Voter Sentiment and Candidate's Party")
@
\caption{\label{moodscree} Screeplot indicating topic contributions to corpus, separated out by levels of Voter Sentiment and Candidate's Party }
\end{figure}

From Figure \ref{moodscree}, we can observe not just what topics are being discussed the most, but also by who and and how they feel. So, for example, if respondents were asked what they disliked about the Democratic candidates, the most likely topic to come up was Topic 53, which references Dukakis and the Prisoner Release program from his home state of Massachusetts. Although first brought up during the 1998 Democratic primary by Al Gore \citep{horton1}, this issue was made particularly salient in the 1988 general election by the infamous ``Willie Horton" ad \citep{horton2}. By contrast, when asked what they most liked about the Democratic candidates, the most common topic is Topic 54, which references the middle and working class.

When asked about what they disliked about the Republican candidate, the most common topic was Topic 25, which references Taxes. It came up most in the 2004 election, after bush lowered taxes 2001 and again in 2003 \citep{bushtaxcuts}, benefiting mostly those Americans with income above the 95th percentile ($\geq \$150,000$) \citep{census2002}.  When asked what they liked about the Republican candidates, Topic 1, referencing the economy, was the most prevalent. Wordclouds for the four topics mentioned from Figure \ref{moodscree}, appear in the next section.

\begin{figure}[H]
<<genderscree, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=2>>=
scree2 %>% 
  nest(-gender) %>% mutate(
    normed = purrr::map(data, normy)
  ) %>% select(gender, normed) %>% unnest() %>%
  ggplot(aes(y=total, x=ord)) +
  geom_text_repel(aes(label=ifelse(ord<11, tops, NA))) +
  geom_point() +
  facet_wrap(~gender) +
  labs(x = 'Order', y = 'Proportion contributed')
@
\caption{\label{genderscree} Screeplot indicating topic contributions to corpus, separated out by voter's gender }
\end{figure}
From Figure \ref{genderscree}, we can see that women appear to be more concerned than men with topic 54, about the Middle and Working Class, although men also discuss this topic at a fairly high rate. 
\begin{figure}[H]
<<eduscree, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=4>>=
scree2 %>% 
      filter(edu!="DK/NA") %>%
  nest(-edu) %>% mutate(
    normed = purrr::map(data, normy)
  ) %>% select(edu, normed) %>% unnest() %>%
  ggplot(aes(y=total, x=ord)) +
  geom_text_repel(aes(label=ifelse(ord<11, tops, NA))) +
  geom_point() +
  facet_wrap(~edu) +
  labs(x = 'Order', y = 'Proportion contributed')
@
\caption{\label{eduscree} Screeplot indicating topic contributions to corpus, separated out by voter's education }
\end{figure}
From Figure \ref{eduscree} we can see that for those with high school or less education, topic 54, concerning the Middle and Working Class, is further above other topics. Whereas for those with a bachelor's degree or beyond, there appears to be less priority on this topic, and there is not a large separation of any topics that ``run away with the conversation", so to speak.
\begin{figure}[H]
<<sentscree, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=2.5>>=
scree2 %>% 
  nest(-feel) %>% mutate(
    normed = purrr::map(data, normy)
  ) %>% select(feel, normed) %>% unnest() %>%
  ggplot(aes(y=total, x=ord)) +
  geom_text_repel(aes(label=ifelse(ord<11, tops, NA))) +
  geom_point() +
  facet_wrap(~feel) +
  labs(x = 'Order', y = 'Proportion contributed')
@
\caption{\label{sentscree} Screeplot indicating topic contributions to corpus, separated out by voter's sentiment }
\end{figure}

From Figure \ref{sentscree}, we are more likely to see respondents bring up The Working or Middle Class (Topic 54) or The Economy (Topic 1) if they like a candidate, whereas they are more likely to bring up Taxes (Topic 25) or Dukakis and the Massachusetts Prisoner Release program (Topic 53) if they dislike a candidate. This reflects what we observed in the previous subsection, from Figure \ref{top54prop}.

\begin{figure}[H]
<<incscree, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=3.5>>=
scree2 %>% 
    filter(income!="DK/NA") %>%
  nest(-income) %>% mutate(
    normed = purrr::map(data, normy)
  ) %>% select(income, normed) %>% unnest() %>%
  ggplot(aes(y=total, x=ord)) +
  geom_text_repel(aes(label=ifelse(ord<11, tops, NA))) +
  geom_point() +
  facet_wrap(~income) +
  labs(x = 'Order', y = 'Proportion contributed')
@
\caption{\label{incscree} Screeplot indicating topic contributions to corpus, separated out by voter's income }
\end{figure}
Figure \ref{incscree} suggests that as voters' income percentile increases, concerns about the Middle and Working Class and the Economy decrease in importance and other Topics, such as Conservative Values (topic 14), Foreign/Generic Policy (topic 11), and Defense Spending (topic 3) rise to the top of their issues.

From Figure \ref{top7scree}, we can see the top 40 words for Topic 07, which pertains to Vice Presidential Nominees and Running Mates, where height indicates how much the word shows up (unnormalized) and red hue indicates the weighted FREX calculation, which is described in the next subsection, where we discuss this in conjunction with Figure \ref{top7FREX}.

\begin{figure}[H]
<<top7scree, echo=FALSE, warning=FALSE,fig.width= 6, fig.height=3>>=
feel.FREX %>% filter(topic==7) %>% 
  arrange(desc(proportion)) %>% slice(1:40) %>%
  ggplot(aes(x=seq(1:length(proportion)), y= proportion, label=words)) + 
  geom_point(aes(color=frex)) +
  geom_text_repel(aes(color=frex, label=ifelse(seq(1:length(proportion))<31,
                                               as.character(words),'')), alpha=0.5, force=2.5) +
    scale_color_gradient(low = "black", high="red") + 
    theme(legend.position = "none")+ 
  labs(y="Contribution to Topic", x="Order")+
    ggtitle("Screeplot for Topic 07")
@
\caption{\label{top7scree} Screeplot for topic 07, about Vice Presidential Nominees and Running Mates}
\end{figure}
\subsection{Wordclouds} \label{wordclouds}
Wordclouds are generated using ggplot \citep{ggplot}. For a given topic, we identify the highest frequency words, and display them in the plot, with word proportion mapped to size such that larger words imply a higher presence within that topic. However, as \citet{stm2013} and \citet{FREX2012} note, high frequency words alone may fail to capture the ``essence" of the topic, since high frequency words may also appear in other topics. To address this, \citet{FREX2012} developed a Frequency-Exclusivity metric, ``FREX", which can combine a particular word's frequency within a given topic and its exclusivity towards other topics. The FREX value for the $v$-th word and the $k$-th topic is computed by:
\begin{equation}
FREX_{k,v} = \Big(\frac{w}{ECDF(\beta_{k,v}/\sum^K_{j=1}\beta_{j,v})} + \frac{1-w}{ECDF(\beta_{k,v})} \Big)^{-1}
\end{equation}
where $w$ is a value chosen by the analyst to distribute weight between Exclusivity (left addend) and Frequency (right addend) (we set it to $w=0.5$), and ECDF is the empirical cumulative distribution function, and $\beta_{k,v}$ indicates the probability of the $v$-th term given the $k$-th topic, as noted in Section (2). 

In order to make our wordclouds more informative, we compute the FREX value for the entire vocabulary, conditioned on the topic, and then map those values to a two color gradient, so that the more exclusive a word is, the more red it will be in the graphic. Thus a term that is both frequent and exclusive will show up large and red, whereas a term that is frequent but less elusive will be a less vibrant shade of red, or even gray or black. Likewise, a term that is less frequent but still exclusive will be smaller, but can still be a brighter red. By combining both the overall prevalence of words within a topic and their FREX values, we present a more cohesive picture of each topic than either metric alone.

\begin{figure}[H]
<<top7FREX, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=3>>=
year.FREX %>%   filter(topic==7) %>% 
  arrange(desc(proportion)) %>% slice(1:50) %>% 
      ggplot(aes( x=1, y=1, size=proportion, label=words) ) +
      geom_text_repel(aes(color=frex),segment.alpha = 0, force = 1) +
      scale_size(range = c(3, 15), guide = FALSE) +
      scale_color_gradient(low = "black", high="red") +
      scale_y_continuous(breaks = NULL) +
      scale_x_continuous(breaks = NULL) +
      labs(x = '', y = '') +
      theme_classic() +
      ggtitle("Topic 07 colored by weighted Exclusivity")
@
\caption{\label{top7FREX} Wordcloud for topic 07, regarding Running Mates and Vice Presidential Candidates}
\end{figure}
From Figure \ref{simcovsA} in a previous subsection, we saw that the rates for topic 07 are higher in 1984 and 1988. From Figure \ref{top7scree} and Figure \ref{top7FREX} we gather that this topic pertains to the selection of Running Mates and the Vice Presidency and its nominee. Notably, in 1984, running against incumbent Ronald Reagan, Democratic presidential nominee Walter Mondale nominated Geraldine Ferraro for his running mate, making her the first woman to be nominated to that role for a major party. This move on Mondale's part was heralded by some as a bold choice and criticized by others as an act of desperation. Presumably, the proportion of this topic remained high in 1988, since George Herbert Walker Bush, then the sitting Vice President, ran to succeed Reagan, his former running mate.  
\begin{figure}[H]
<<seltopsFREX, echo=FALSE, warning=FALSE, fig.width= 7.7, fig.height=5>>=
year.FREX %>% filter(topic==1 | topic==25 | topic==53 | topic==54) %>% nest(-topic) %>%
  mutate(vals = purrr::map(data, chop1)) %>% select(topic, vals) %>% unnest() %>% 
  mutate(topic = as.factor(topic),
         topic = fct_recode(topic,c(
           "economy" = "1",
           "Taxes" = "25",
           "Dukakis/Prisoner release" = "53",
           "Middle/working class" = "54"))) %>%
  ggplot(aes( x=1, y=1, size=proportion, label=words) ) +
  geom_text_repel(aes(color=frex),segment.alpha = 0, force = 1) +
  scale_size(range = c(3, 15), guide = FALSE) +
  scale_color_gradient(low = "black", high="red") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) +
  facet_wrap(~topic) +
  labs(x = '', y = '') +
  theme_classic() +
  ggtitle("Selected topics colored by weighted Exclusivity")
@
\caption{\label{seltopsFREX} Wordclouds for topics 1, 25, 53, and 54}
\end{figure}

The topics referenced in Figure \ref{moodscree} are shown in Figure \ref{seltopsFREX}. It is interesting that topic 53 makes this list, since it is particular to the 1988 election, whereas the other three topics listed here are topics that generalize across every election year.

Additional wordclouds are created to inspect the ways in which one of two content covariates influence word selection within a topic. We considered two models, one with Voter sentiment (like/dislike) (see Figure \ref{feelclouds1a}, below, and Figures \ref{feelclouds1b}  and \ref{feelclouds1c}, appendix) assigned as the content covariate, and the other with Candidate Party (Democrat/Republican) (see Figure \ref{partyQclouds1a}, below, and \ref{partyQclouds1b}  and \ref{partyQclouds1c}, appendix) mapped to the content covariate, to see if either of these influenced \textit{how} respondents discussed topics. 

Here again, we map the proportion with which a word shows up in a given topic to the size of the term in the plot. But for a given term, now we map how much the term's frequency, conditioned on selected topic, content covariate level, and their interactions, deviates from the prevalence of that term across the corpus to a three color gradient, with gray being the central color. Terms that are not particularly ``biased" towards either level of the content covariate are mapped towards the center of the gradient, whereas terms that are more likely for one level or the other are mapped to the corresponding color.

\begin{figure}[H]
<<feelclouds1a, echo=FALSE, warning=FALSE, fig.width= 8.2, fig.height=9.5>>=
feel.clouds1 %>% filter(topic %in% 1:20) %>%
  ggplot(aes( x=1, y=1, size=proportion, label=words) ) +
  geom_text_repel(aes(color=difs), segment.alpha = 0, force = 1) +
  scale_size(range = c(3, 15), guide = FALSE) +
  scale_color_gradient2(guide=guide_colorbar(title="sentiment"),
                        breaks = c(-150000, 0,130000 ),
                        labels = c("like", "0", "dislike"),
    low = "purple", mid="gray", high="green") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) +
  labs(x = '', y = '') +
  theme_classic() +  facet_wrap(~topicf, ncol=4)+
  theme(legend.position = "none")
@
\caption{\label{feelclouds1a} Differences in vocabulary choice for sentiment Covariate for topics 1 through 20. Purple indicates like, whereas green indicates dislike. }
\end{figure}

\begin{figure}[H]
<<partyQclouds1a, echo=FALSE, warning=FALSE, fig.width= 8.2, fig.height=9.5>>=
partyQ.clouds1 %>%filter(topic %in% 1:20) %>%
  ggplot(aes( x=1, y=1, size=proportion, label=words) ) +
  geom_text_repel(aes(color=difs), segment.alpha = 0, force = 1) +
  scale_size(range = c(3, 15), guide = FALSE) +
  scale_color_gradient2(guide=guide_colorbar(title="candidate"),
                        breaks = c(-275000, 0,270000 ),
                        labels = c("Republican", "0", "Democrat"),
                        low = "red", mid="gray", high="blue") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) +
  labs(x = '', y = '') +
  theme_classic() +  facet_wrap(~topicf) +
  theme(legend.position = "none")

@
\caption{\label{partyQclouds1a} Differences in vocabulary for candidate for topics 1 through 20. Red indicates Republican candidate whereas blue indicates Democratic candidate.}
\end{figure}


At the suggestion of \citet{stm2016}, while in theory we could assign a more complicated set of  covariates to the content covariate of the model, going from no content covariate to a categorical content covariate with two levels doubles the number of parameters of the model. Two content covariates each with two factor levels would quadruple the number of parameters, and so forth. Thus, as we explored the STM, in the models we tried which incorporated content covariates, we opted for covariates that only had at most two factor levels which exhaustively captured all documents. 

\section{Conclusions and Future Work} %for someone else

The relative novelty of STM coupled with its flexibility is simultaneous blessing and a curse. Even with a deeper knowledge of stats, examining/understanding/interpreting models is not entirely straight forward. As it currently stands, many social scientists and humanities scholars may lack the necessary background knowledge to truly utilize STM's potential, particularly if their models of interest have any complexity.

To that end, more research is need to develop methods to assess and quantify model and parameter fits. Some way to compare similar models, such as models which are nested within one another or models with only slightly different numbers of topics, could greatly aid in this endeavor. For the time being, it is unclear if adding covariates to the models better or worse, nor is it clear what ``better" or ``worse" even mean in this context. We remain hopeful that as more scholars continue to explore topic models in general and STM in particular, that more straightforward diagnostics will be developed.

As with statistics broadly, some of the craft is an art more than a science. The selection of topic number currently lives more firmly in the former, but hopefully it will move towards the latter with time. Perhaps with the continuing exponential growth of computing power, topic model fitting will continue to grow, and the concerns outlined above will become trivial. This may become particularly true if methods could be developed to parallelize some of the computations that are currently required to estimate STM and other topic models. 

One idea to incorporate additional diagnostics into topic modeling, to assess if the models are truly recovering coherent topics, could be through the use of Visual inference, as suggested in work like \citet{vizinf}. For example, in addition to showing topics to political science experts, topic assessment could be crowd sourced through services like Amazon's Mechanical Turk, where it is fairly easy to gather large numbers of responses from lay people in a fairly short amount of time, and for relatively low costs. Such an endeavor might involve selecting a topic from the model, then generating multiple random ``dummy" topics, generating word clouds for each, and then seeing if the respondents are able to recover the correct topic with any level of reliability. Desired $\alpha$ levels can be attained by generating $n$ dummy topics such that $\frac{1}{n+1} = \alpha$, creating an analog to a hypothesis test. Such an experimental design need not even be limited to lay people, and could be given to scholars in political science as well. 

But despite its limitations and complications, the Structural Topic Modeling is a fascinating, cutting edge area of development in Machine Learning and Natural Language Processing, presenting an exciting and versatile tool for researchers on the frontiers of the Social Sciences and Humanities. 


\newpage 
\bibliographystyle{asa}

\bibliography{references}

\newpage
\appendix

\section{Faceted proportion plots, conditioned on a particular demographic covariates}

Plots in this appendix show the prevalence of a topic, conditioned on election year, party ID, and one other demographic covariate, as indicated in the plot. For each covariate, the overall group of topics is split in half, to allow more detail of the plots to come through.

\begin{figure}[H]
<<racecovsA, echo=FALSE, fig.width= 7.7, fig.height=8.5>>=
race.int2.FX %>%  filter(topic %in% 1:30) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=race)) +
  guides(shape=guide_legend(title="Voter \n Race"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year based on Voter Party and Race")
@
\caption{\label{racecovsA} Proportions for topics 1 through 30 based on voter's race and Party ID}
\end{figure}

\begin{figure}[H]
<<racecovsB, echo=FALSE, fig.width= 7.7, fig.height=8.5>>=
race.int2.FX %>%  filter(topic %in% 31:60) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=race)) +
  guides(shape=guide_legend(title="Voter \n Race"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year based on Voter Party and Race")
@
\caption{\label{racecovsB} Proportions for topics 31 through 60 based on voter's race and Party ID}
\end{figure}

\begin{figure}[H]
<<gendercovsA, echo=FALSE, fig.width= 7.7, fig.height=8.5>>=
gen.int2.FX %>%  filter(topic %in% 1:30) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=gender)) +
    guides(shape=guide_legend(title="Voter \n Gender"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year based on Voter Party and Gender")
@
\caption{\label{gendercovsA} Proportions for topics 1 through 30 based on voter's gender identification and Party ID}
\end{figure}

\begin{figure}[H]
<<gendercovsB, echo=FALSE, fig.width= 7.7, fig.height=8.5>>=
gen.int2.FX %>%  filter(topic %in% 31:60) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=gender)) +
    guides(shape=guide_legend(title="Voter \n Gender"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year based on Voter Party and Gender")
@
\caption{\label{gendercovsB} Proportions for topics 31 through 60 based on voter's gender identification and Party ID}
\end{figure}


\begin{figure}[H]
<<educovsA, echo=FALSE, fig.width= 7.7, fig.height=8.5>>=
edu.int2.FX %>%  filter(topic %in% 1:30) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
  filter(edu!="DK/NA") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=edu)) +
    guides(shape=guide_legend(title="Voter \n Education"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year based on Voter Party and Education")
@
\caption{\label{educovsA} Proportions for topics 1 through 30 based on voter's educational attainment and Party ID}
\end{figure}

\begin{figure}[H]
<<educovsB, echo=FALSE, fig.width= 7.7, fig.height=8.5>>=
edu.int2.FX %>%  filter(topic %in% 31:60) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
  filter(edu!="DK/NA") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=edu)) +
    guides(shape=guide_legend(title="Voter \n Education"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year based on Voter Party and Education")
@
\caption{\label{educovsB} Proportions for topics 31 through 60 based on voter's educational attainment and Party ID}
\end{figure}


\begin{figure}[H]
<<inccovsA, echo=FALSE, warning=FALSE, fig.width= 7.7, fig.height=8.5>>=
inc.int2.FX %>%  filter(topic %in% 1:30) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
  filter(income!="DK/NA") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=income)) +
    guides(shape=guide_legend(title="Income \n Percentile"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year based on Voter Party and Income Percentile")
@
\caption{\label{inccovsA} Proportions for topics 1 through 30 based on voter's income percentile and Party ID}
\end{figure}

\begin{figure}[H]
<<inccovsB, echo=FALSE, warning=FALSE, fig.width= 7.7, fig.height=8.5>>=
inc.int2.FX %>%  filter(topic %in% 31:60) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
  filter(income!="DK/NA") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=income)) +
    guides(shape=guide_legend(title="Income \n Percentile"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year based on Voter Party and Income Percentile")
@
\caption{\label{inccovsB} Proportions for topics 31 through 60 based on voter's income percentile and Party ID}
\end{figure}

\begin{figure}[H]
<<idecovsA, echo=FALSE, warning=FALSE, fig.width= 7.7, fig.height=8.5>>=
ide.int2.FX %>%  filter(topic %in% 1:30) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
  filter(ideof!="none") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=ideof)) +
    guides(shape=guide_legend(title="Voter \n Ideology"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year based on Voter Party and Ideology")
@
\caption{\label{idecovsA} Proportions for topics 1 through 30 based on voter's income percentile and Party ID}
\end{figure}

\begin{figure}[H]
<<idecovsB, echo=FALSE, warning=FALSE, fig.width= 7.7, fig.height=8.5>>=
ide.int2.FX %>%  filter(topic %in% 31:60) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
  filter(ideof!="none") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=ideof)) +
    guides(shape=guide_legend(title="Voter \n Ideology"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year based on Voter Party and Ideology")
@
\caption{\label{idecovsB} Proportions for topics 31 through 60 based on voter's income percentile and Party ID}
\end{figure}

\begin{figure}[H]
<<chucovsA, echo=FALSE, warning=FALSE, fig.width= 7.7, fig.height=8.5>>=
chu.int2.FX %>%  filter(topic %in% 1:30) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
  filter(church=="Ev.Week"|
           church=="Al.Ev.Week"|
           church=="Monthly"|
           church=="FewYear"|
           church=="Never") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=church)) +
    guides(shape=guide_legend(title="Church \n Attendence"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year \n based on Voter Party and Church Attendence")
@
\caption{\label{chucovsA} Proportions for topics 1 through 30 based on voter's income percentile and Party ID}
\end{figure}

\begin{figure}[H]
<<chucovsB, echo=FALSE, warning=FALSE, fig.width= 7.7, fig.height=8.5>>=
chu.int2.FX %>%  filter(topic %in% 1:30) %>%
  filter(partyID == "Rep" | 
         partyID == "Ind" | 
         partyID == "Dem") %>%
  filter(church=="Ev.Week"|
           church=="Al.Ev.Week"|
           church=="Monthly"|
           church=="FewYear"|
           church=="Never") %>%
   ggplot(aes(x=yearf, y=beta)) +
  geom_point(aes(color=partyID, shape=church)) +
    guides(shape=guide_legend(title="Church \n Attendence"), color=guide_legend(title="Voter \n Party")) +
  facet_wrap(~topicf, ncol=3) + 
 # theme(legend.position = "none") + 
  ylab("Topic Proportion") +
  xlab("Presidential Election Year") +
   theme(axis.text.x=element_text(angle=90), plot.title = element_text(hjust=0.5)) +
    ggtitle("Mean Topic Proportions for each Election Year \n based on Voter Party and Church Attendence")
@
\caption{\label{chucovsB} Proportions for topics 31 through 60 based on voter's income percentile and Party ID}
\end{figure}

\section{Wordclouds}

\begin{figure}[H]
<<feelclouds1b, echo=FALSE, warning=FALSE, fig.width= 8.2, fig.height=9.5>>=
feel.clouds1 %>% filter(topic %in% 21:40) %>%
  ggplot(aes( x=1, y=1, size=proportion, label=words) ) +
  geom_text_repel(aes(color=difs), segment.alpha = 0, force = 1) +
  scale_size(range = c(3, 15), guide = FALSE) +
  scale_color_gradient2(guide=guide_colorbar(title="sentiment"),
                        breaks = c(-150000, 0,130000 ),
                        labels = c("like", "0", "dislike"),
    low = "purple", mid="gray", high="green") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) +
  labs(x = '', y = '') +
  theme_classic() +  facet_wrap(~topicf, ncol=4)+
  theme(legend.position = "none")
@
\caption{\label{feelclouds1b} Differences in vocabulary choice for sentiment Covariate for topics 21 through 40. Purple indicates like, whereas green indicates dislike. }
\end{figure}

\begin{figure}[H]
<<feelclouds1c, echo=FALSE, warning=FALSE, fig.width= 8.2, fig.height=9.5>>=
feel.clouds1 %>% filter(topic %in% 41:60) %>%
  ggplot(aes( x=1, y=1, size=proportion, label=words) ) +
  geom_text_repel(aes(color=difs), segment.alpha = 0, force = 1) +
  scale_size(range = c(3, 15), guide = FALSE) +
  scale_color_gradient2(guide=guide_colorbar(title="sentiment"),
                        breaks = c(-150000, 0,130000 ),
                        labels = c("like", "0", "dislike"),
    low = "purple", mid="gray", high="green") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) +
  labs(x = '', y = '') +
  theme_classic() +  facet_wrap(~topicf, ncol=4)+
  theme(legend.position = "none")
@
\caption{\label{feelclouds1c} Differences in vocabulary choice for sentiment Covariate for topics 41 through 60. Purple indicates like, whereas green indicates dislike. }
\end{figure}


\begin{figure}[H]
<<partyQclouds1b, echo=FALSE, warning=FALSE, fig.width= 8.2, fig.height=9.5>>=
partyQ.clouds1 %>%filter(topic %in% 21:40) %>%
  ggplot(aes( x=1, y=1, size=proportion, label=words) ) +
  geom_text_repel(aes(color=difs), segment.alpha = 0, force = 1) +
  scale_size(range = c(3, 15), guide = FALSE) +
  scale_color_gradient2(guide=guide_colorbar(title="candidate"),
                        breaks = c(-275000, 0,270000 ),
                        labels = c("Republican", "0", "Democrat"),
                        low = "red", mid="gray", high="blue") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) +
  labs(x = '', y = '') +
  theme_classic() +  facet_wrap(~topicf, ncol=4) +
  theme(legend.position = "none")

@
\caption{\label{partyQclouds1b} Differences in vocabulary for candidate for topics 21 through 40. Red indicates Republican candidate whereas blue indicates Democratic candidate.}
\end{figure}


\begin{figure}[H]
<<partyQclouds1c, echo=FALSE, warning=FALSE, fig.width= 8.2, fig.height=9.5>>=
partyQ.clouds1 %>%filter(topic %in% 41:60) %>%
  ggplot(aes( x=1, y=1, size=proportion, label=words) ) +
  geom_text_repel(aes(color=difs), segment.alpha = 0, force = 1) +
  scale_size(range = c(3, 15), guide = FALSE) +
  scale_color_gradient2(guide=guide_colorbar(title="candidate"),
                        breaks = c(-275000, 0,270000 ),
                        labels = c("Republican", "0", "Democrat"),
                        low = "red", mid="gray", high="blue") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = NULL) +
  labs(x = '', y = '') +
  theme_classic() +  facet_wrap(~topicf, ncol=4) +
  theme(legend.position = "none")

@
\caption{\label{partyQclouds1c} Differences in vocabulary for candidate for topics 41 through 60. Red indicates Republican candidate whereas blue indicates Democratic candidate.}
\end{figure}

\newpage

The following plots display the forty most frequent words for each topic. Words are colored using the FREX computation described in section \ref{wordclouds}.

<<allclouds, echo=FALSE, warning=FALSE, fig.width= 7, fig.height=2.9>>=
for (i in 1:60){
print(feel.FREX %>% 
  filter(topic==i) %>% arrange(desc(proportion)) %>% slice(1:40) %>% 
      ggplot(aes( x=1, y=1, size=proportion, label=words) ) +
      geom_text_repel(aes(color=frex),segment.alpha = 0, force = 1) +
      scale_size(range = c(3, 15), guide = FALSE) +
      scale_color_gradient(low = "black", high="red") +
      scale_y_continuous(breaks = NULL) +
      scale_x_continuous(breaks = NULL) +
      labs(x = '', y = '') +
      theme_classic() +
      ggtitle(paste("Topic",i, sep=" "))
  )
}
@

\newpage
\section{Screeplots}


\begin{figure}[H]
<<chuscree, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=2.7>>=
scree2 %>% 
     filter(church=="Ev.Week"|
           church=="Al.Ev.Week"|
           church=="Monthly"|
           church=="FewYear"|
           church=="Never") %>%
  nest(-church) %>% mutate(
    normed = purrr::map(data, normy)
  ) %>% select(church, normed) %>% unnest() %>%
  ggplot(aes(y=total, x=ord)) +
  geom_text_repel(aes(label=ifelse(ord<11, tops, NA))) +
  geom_point() +
  facet_wrap(~church) +
  labs(x = 'Order', y = 'Proportion contributed')
@
\caption{\label{chuscree} Screeplot indicating topic contributions to corpus, separated out by voter's church attendance }
\end{figure}

\begin{figure}[H]
<<racescree, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=2.7>>=
scree2 %>% 
  nest(-race) %>% mutate(
    normed = purrr::map(data, normy)
  ) %>% select(race, normed) %>% unnest() %>%
  ggplot(aes(y=total, x=ord)) +
  geom_text_repel(aes(label=ifelse(ord<11, tops, NA))) +
  geom_point() +
  facet_wrap(~race) +
  labs(x = 'Order', y = 'Proportion contributed')
@
\caption{\label{racescree} Screeplot indicating topic contributions to corpus, separated out by voter's race }
\end{figure}

\begin{figure}[H]
<<idescree, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=2.7>>=
scree2 %>% 
    filter(ideof!="none") %>%
  nest(-ideof) %>% mutate(
    normed = purrr::map(data, normy)
  ) %>% select(ideof, normed) %>% unnest() %>%
  ggplot(aes(y=total, x=ord)) +
  geom_text_repel(aes(label=ifelse(ord<11, tops, NA))) +
  geom_point() +
  facet_wrap(~ideof) +
  labs(x = 'Order', y = 'Proportion contributed')
@
\caption{\label{idescree} Screeplot indicating topic contributions to corpus, separated out by voter's ideology }
\end{figure}

\newpage

The following plots display the frequency of the 40 words with the highest contribution to each topic, plotted against the ranking of their frequency. The 

<<allscree, echo=FALSE, warning=FALSE, fig.width= 6, fig.height=2.6>>=
for (i in 1:60){
  print(feel.FREX %>% filter(topic==i) %>% 
    arrange(desc(proportion)) %>% slice(1:40) %>%
    ggplot(aes(x=seq(1:length(proportion)), y= proportion)) + 
    geom_point(aes(color=frex)) +
    geom_text_repel(aes(color=frex, label=ifelse(seq(1:length(proportion))<31,
                                               as.character(words),'')),alpha=0.5, force=2.5) +
    scale_color_gradient(low = "black", high="red") + 
      labs(x="Order", y="Contribution") +
    theme(legend.position = "none")+ 
    ggtitle(paste("Topic", i, sep = " "))
  )
}
@



\end{document}